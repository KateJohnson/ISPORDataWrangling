---
title: "Data Wrangling in R for Health Outcomes Research"
output: github_document
keep.md: true
---

The objective of this workshop is to provide an introduction to data wrangling in R using the tidyverse. By the end of this workshop, you should be able to:

1. Use a project oriented workflow and an R markdown document.
2. Perform simple data manipulations using the 5 dplyr verbs (`select`, `filter`, `arrange`, `mutate`, `summarise`, `group_by`), and chain these operations together using piping (`%>%`).
3. Join datasets together using the set of `join` functions.


## Objective 1: Setting up our workflow

First, let's load the [tidyverse](https://www.tidyverse.org/), which is an "an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures." The operate in parallel to, and often in place of, the set of packages included in base R.

```{r}
#install.packages("tidyverse")
library(tidyverse)

# some other packages that we'll need down the road
#install.packages("here")
library(here)
#install.packages("readr")
library(readr)
```


For this workshop, we're going to work with a dataset from the National Institute of Diabetes and Digestive and Kidney Diseases that I pulled from [kaggle](https://www.kaggle.com). The data was collected for the purpose of developing a model to predict the occurence of diabetes mellitus among a group of Pima Indians. You can find more details on the data [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database).

Let's load the data into R and check it out:

```{r}
diabetes <- read_csv(here("Data/diabetes.csv"))
```


(Aside: Check out this [this](https://www.tidyverse.org/articles/2017/12/workflow-vs-script/) blogpost by Jenny Bryan about best practices for getting your data into R. *Hint:* if you use code like this: 'rm(list=ls())' she will *set your computer on fire.* 

## Explore the data

So what do we have here?

```{r}
glimpse(diabetes)
```

Let's get some basic summaries of each of the variables so that we have an idea of what's in there:

```{r}
summary(diabetes)
```

What are some things we might want to check when we first bring our data into R? Let's list them here:

  - ...


## Objective 2: Data manipulations using dplyr

(This summary is taken from the [STAT 545](http://stat545.com/) class notes.)

The six main dplyr functions for data manipulation are:

> - Pick variables by their names (`select()`).
> - Pick observations by their values (`filter()`).
> - Reorder the rows (`arrange()`).
> - Create new variables with functions of existing variables (`mutate()`).
> - Collapse many values down to a single summary (`summarise()`).

Then there's `group_by()`, which can be used in conjunction with all of these.

And `%>%` (piping) joins them all together into one happy family. 

---

### 1. `select()` works on variables

Let's get started with the first of our dplyr verbs, `select()`.

```{r}
select(diabetes, ID, Pregnancies, Glucose)
```

Or, equivalently:

```{r}
select(diabetes, ID:Glucose)
```

But be careful with not explicitly referencing variables, and *please* don't do this:

```{r}
select(diabetes, 1,2,3)
```

`select()` has a lot of handy tricks:

  - `everything()` to select all variables
  - `-` to drop variables. 
  - Use `=` within select to rename variables (*New_name = Old_name*)
  - Reposition variables based on their order in `select()`
  
I want to make Diabetes the first variable in my dataframe:

```{r}
select(diabetes, Diabetes, everything())
```


---

### 2. `filter()` works on rows

Select works on columns, and `filter()` works on rows.

Some useful logical expressions to refer back to: 

Logical expressions are governed by __relational operators__, that output either `TRUE` or `FALSE` based on the validity of the statement you give it. Here's a summary of the operators:

| Operation | Outputs `TRUE` or `FALSE` based on the validity of the statement... |
| ------ | ----- |
| `a == b` | `a` is equal to `b` |
| `a != b` | `a` is not equal to `b`. |
| `a > b` | `a` is greater than `b`. |
| `a < b` | `a` is less than `b`. |
| `a >= b` | `a` is greater than or equal to `b`. |
| `a <= b` | `a` is less than or equal to `b`. |
| `a %in% b` | `a` is an element in `b`. | 

(Full credit to [STAT 545](http://stat545.com/) for this handy table)


Let's start by filtering all observations in which blood glucose levels are greater than 100.

```{r}
filter(diabetes, Glucose>100)
```

How about only data for people who are Obsese?

```{r}
filter(diabetes, BMI=="Obese")
```

Now I want people who are obsese or morbidly obese.

```{r}
filter(diabetes, BMI=="Obese" | BMI=="Morbidly Obese")
```

**Exercises**

1. Can you think of another way to select obese and morbidly obese people?


2. Filter observations for people who are 25 to 50 years old.


---

### 3. `arrange()` changes the order of rows

Now that we've got `select` and `filter()` covered. Let's slip in `arrange()` quickly.

```{r}
arrange(diabetes, ID)
```

We can arrange by multiple variables. You can `desc()` too.

Ordered by BMI, and then from oldest to youngest.

```{r}
arrange(diabetes, BMI, desc(Age))
```

How is arrange handling a categorical variable?


---

### 4. `%>%` chains operations together

Alrighty then, now that we've got `select()`, `filter()` and `arrange()`, let's `%>%` them together!

The power of piping:

```{r}
diabetes %>%
      select(id=ID, Glucose, Diabetes) %>%
        filter(Glucose <= 100) %>%
          arrange(id)
```

Another example:

```{r}
diabetes %>% 
    filter(BMI=="Obese", Age>=50) %>% 
      select(ID, Diabetes, BloodPressure) %>% 
        arrange(desc(BloodPressure))
```

What's happening here? Let's write it down:

  - ...


Now that we're familiar with `%>%`, let's keep using it as we learn our remaining two verbs: `mutate()` and `summarise()`


### Use `mutate()` to create new variables


I want diabetes pedigree function to be expressed as a percentage.

```{r}
diabetes %>% 
  mutate(DiabetesPedigreePercent= DiabetesPedigreeFunction * 100)
```

**Exercise:** Make a new variable called "GlucoseDiff", which equals the difference between each patient's glucose level and the average glucose level for all patients. Then reduce the dataset to only the "ID", "Glucose", and "GlucoseDiff" variables.

```{r}
diabetes %>% 
    mutate(GlucoseDiff= Glucose - mean(Glucose)) %>% 
      select(ID, Glucose, GlucoseDiff)
```


### We can `summarise()` our data

Our last verb is used to create aggregated summarises our data. It is especially helpful when used in conjuction with `group_by()`


Let's start with some counting. The `n()` function is good for this.

How many people do we have in each BMI category?

```{r}
diabetes %>% 
    group_by(BMI) %>% 
      summarise(number = n())
```

`tally()` can do the same thing as `summarise( n() )` here.


Let's see if there might be some relation betwen BMI and age, by calculating the average age and standard deviation within each BMI category. 

```{r}
diabetes %>% 
  group_by(BMI) %>% 
    summarise(AverageAge= mean(Age), SDAge= sd(Age))
```

Now I want to know the average age *and* the proportion of people with diabetes in each BMI category.

```{r}
diabetes %>% 
  group_by(BMI, Diabetes) %>% 
    summarise(AverageAge= mean(Age), Number = n()) %>% 
      mutate(Prop= Number/sum(Number))
```



### Challenge exercises

Your turn! 

1. Let's answer a question. Which variables are the most different between people who have diabetes, and people who don't? A few hints to get you started:

  - We're going to want to express all continous variables in common terms. The 'scale()' function will be helpful with this. For each observation, `scale()` subtracts the mean and divides by the standard deviation for all observations in that variable. This is akin to z-scores in statistical speak, and it will make all variables comparable on the same units.
  - For categorical variables, we could determine the number of observations in each level of the variable, and compare the counts between people with and without diabetes. 


```{r}
diabetes %>% 
    mutate()
```


---
Some other verbs that are part of the tidyverse and therefore very `%>%`able:

  - `count()`: very similar to `table()` from base R.  
  - `slice()`: reference rows to keep (or drop)
  - `lag()`: lag a row x number of times
  - `first()`: select the first row (in a group for example)
  - `replace_na()`: replace NA with another value
  - `rowwise()`: the opposite of `group_by()`
----

